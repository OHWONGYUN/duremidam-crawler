# crawlers/snuco_crawler.py

import requests
from bs4 import BeautifulSoup
import config
import logging
import datetime

class SnucoCrawler:
    def __init__(self, cafeteria_name):
        self.name = cafeteria_name
        self.url = config.SNUCO_URL
        self.logger = logging.getLogger(__name__)

    def _parse_menu_text(self, meal_cell_text):
        """ë©”ë‰´ê°€ ë‹´ê¸´ table cellì˜ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
        # splitlines()ë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ ë¼ì¸ë³„ë¡œ ë‚˜ëˆ”
        raw_lines = meal_cell_text.strip().splitlines()
        
        menu_items = []
        for line in raw_lines:
            # ê³µë°± ì œê±°
            item = line.strip()
            # ê°€ê²© ì •ë³´, ë¹ˆ ì¤„, íŠ¹ì • ë‹¨ì–´ë“¤ ì œì™¸
            if item and not item.endswith('ì›') and 'ì½”ë„ˆ' not in item and 'ë©”ë‰´' not in item:
                menu_items.append(item)
        return menu_items

    def crawl(self):
        self.logger.info(f"ğŸš€ '{self.name}' ë©”ë‰´ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        today_str = datetime.date.today().strftime('%Y-%m-%d')
        full_url = f"{self.url}?date={today_str}"
        self.logger.info(f"ì ‘ì†í•  URL: {full_url}")
        
        try:
            response = requests.get(full_url)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"'{self.name}' í¬ë¡¤ë§ ì‹¤íŒ¨: ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            return None
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # --- ğŸ‘‡ğŸ‘‡ğŸ‘‡ 'ì‹ìƒ¤'ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •ëœ ìµœì¢… ë¡œì§ì…ë‹ˆë‹¤! ğŸ‘‡ğŸ‘‡ğŸ‘‡ ---
        
        # 1. 'menu-table' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ <table>ì„ ì°¾ìŠµë‹ˆë‹¤.
        table = soup.find("table", class_="menu-table")
        if not table:
            self.logger.warning("í˜ì´ì§€ì—ì„œ 'menu-table'ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

        final_menu = {'lunch': [], 'dinner': []}
        found = False

        # 2. í…Œì´ë¸”ì˜ ëª¨ë“  í–‰(<tr>)ì„ ìˆœíšŒí•©ë‹ˆë‹¤. ê° í–‰ì€ ì‹ë‹¹ í•˜ë‚˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
        for row in table.find_all("tr"):
            # 3. í–‰ì˜ ëª¨ë“  ì…€(<td>)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            cells = row.find_all("td")
            if not cells:
                continue

            # 4. ì²« ë²ˆì§¸ ì…€(cells[0])ì—ì„œ ì‹ë‹¹ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            restaurant_name_from_web = cells[0].get_text(strip=True)
            
            # 5. ìš°ë¦¬ê°€ ì°¾ë˜ ì‹ë‹¹ ì´ë¦„ì´ ë§ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
            if self.name in restaurant_name_from_web:
                found = True
                
                # 6. ë‚˜ë¨¸ì§€ ì…€ë“¤(cells[1:])ì„ ìˆœíšŒí•˜ë©° ì ì‹¬, ì €ë… ë©”ë‰´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                for cell in cells[1:]:
                    # 'class' ì†ì„±ì„ ì´ìš©í•´ ì ì‹¬('lunch')ê³¼ ì €ë…('dinner')ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
                    if 'lunch' in cell.get('class', []):
                        final_menu['lunch'] = self._parse_menu_text(cell.text)
                    elif 'dinner' in cell.get('class', []):
                        final_menu['dinner'] = self._parse_menu_text(cell.text)
                break # ì‹ë‹¹ì„ ì°¾ì•˜ìœ¼ë‹ˆ ë” ì´ìƒ ìˆœíšŒí•  í•„ìš” ì—†ìŒ
        
        # -----------------------------------------------------------------

        if not found:
            self.logger.warning(f"'{self.name}'ì„ í˜ì´ì§€ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì‹ë‹¹ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
             self.logger.info(f"ğŸ‘ '{self.name}' ë©”ë‰´ í¬ë¡¤ë§ ì™„ë£Œ.")
             self.logger.info(f"ì ì‹¬: {final_menu['lunch']}")
             self.logger.info(f"ì €ë…: {final_menu['dinner']}")
        return final_menu