# crawlers/snuco_crawler.py

import requests
from bs4 import BeautifulSoup
import config
import logging
import datetime as dt
from pytz import timezone

class SnucoCrawler:
    def __init__(self, cafeteria_name):
        self.name = cafeteria_name
        self.url = config.SNUCO_URL
        self.logger = logging.getLogger(__name__)

    # --- ğŸ‘‡ğŸ‘‡ğŸ‘‡ 'ë‘ë ˆë¯¸ë‹´' ì „ìš© ë¡œì§ì´ ì¶”ê°€ëœ ìµœì¢… ì •ì œ í•¨ìˆ˜ì…ë‹ˆë‹¤! ğŸ‘‡ğŸ‘‡ğŸ‘‡ ---
    def _parse_menu_text(self, meal_cell_text):
        raw_lines = meal_cell_text.strip().splitlines()
        menu_items = []

        # 'ë‘ë ˆë¯¸ë‹´'ì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if self.name == "ë‘ë ˆë¯¸ë‹´":
            is_self_corner = False
            for line in raw_lines:
                item = line.strip()
                
                # <ì…€í”„ì½”ë„ˆ>ë¥¼ ë§Œë‚˜ë©´ ìˆ˜ì§‘ ì‹œì‘
                if '<ì…€í”„ì½”ë„ˆ>' in item:
                    is_self_corner = True
                    continue
                
                # <ì£¼ë¬¸ì‹ ë©”ë‰´>ë¥¼ ë§Œë‚˜ë©´ ìˆ˜ì§‘ ì¤‘ë‹¨
                if '<ì£¼ë¬¸ì‹ ë©”ë‰´>' in item:
                    break
                
                # ì…€í”„ì½”ë„ˆ êµ¬ê°„ì—ì„œ, 'ì˜¤ëŠ˜ì˜ì°¨'ì™€ ë¹ˆ ì¤„ì„ ì œì™¸í•˜ê³  ìˆ˜ì§‘
                if is_self_corner and item and 'ì˜¤ëŠ˜ì˜ì°¨' not in item:
                    menu_items.append(item)
        
        # ê·¸ ì™¸ ì‹ë‹¹(í•™ìƒíšŒê´€ ë“±)ì˜ ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        else:
            for line in raw_lines:
                item = line.strip()
                if not item or item.startswith('â€»'):
                    continue
                menu_name = item.split(':')[0].strip()
                if menu_name:
                    menu_items.append(menu_name)
                    
        return menu_items
    # -----------------------------------------------------------------------

    def crawl(self, date_str):
        self.logger.info(f"ğŸš€ '{self.name}' ë©”ë‰´ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        full_url = f"{self.url}?date={date_str}"
        self.logger.info(f"ì ‘ì†í•  URL: {full_url} (ì„œìš¸ ê¸°ì¤€)")
        
        try:
            response = requests.get(full_url)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"'{self.name}' í¬ë¡¤ë§ ì‹¤íŒ¨: ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            return None
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        table = soup.find("table", class_="menu-table")
        if not table:
            self.logger.warning("í˜ì´ì§€ì—ì„œ 'menu-table'ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

        final_menu = {'lunch': [], 'dinner': []}
        found = False

        for row in table.find_all("tr"):
            cells = row.find_all("td")
            if not cells:
                continue

            restaurant_name_from_web = cells[0].get_text(strip=True)
            
            if self.name in restaurant_name_from_web:
                found = True
                
                for cell in cells[1:]:
                    if 'lunch' in cell.get('class', []):
                        final_menu['lunch'] = self._parse_menu_text(cell.text)
                    elif 'dinner' in cell.get('class', []):
                        final_menu['dinner'] = self._parse_menu_text(cell.text)
                break
        
        if not found:
            self.logger.warning(f"'{self.name}'ì„ í˜ì´ì§€ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì‹ë‹¹ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
             self.logger.info(f"ğŸ‘ '{self.name}' ë©”ë‰´ í¬ë¡¤ë§ ì™„ë£Œ.")
             self.logger.info(f"ì ì‹¬: {final_menu['lunch']}")
             self.logger.info(f"ì €ë…: {final_menu['dinner']}")
        return final_menu